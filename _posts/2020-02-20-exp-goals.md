---
layout: post
title: A fully transparent expected-goals model (**work in progress**)
---
See [this](https://github.com/RobBlumberg/xg_model) GitHub repository for all code used in this project. 

## Introduction

The concept of "Expected Goals" (xG for short), is a widely used metric among soccer analysts and fans alike. In fact, the idea of xG has infiltrated the mainstream in recent years, to the point where now, even most casual fans have probably heard of the term. The xG metric essentially describes how many goals we'd expect a team to score based on the chances it creates. Each shot a team takes can be assigned an xG value, ranging from 0 to 1, which represents the probability of that shot resulting in a goal. The xG metric helps provide objectivity in the analysis of a soccer match, since actual score lines can often be misleading given that luck plays such a large role in the game. 

Despite its rising popularity, a stigma has developped around xG, as soccer traditionalists and skeptics have questioned its use. One of the main reasons for this skepticism is likely based on fans' poor understanding of how xG is actually calculated. Many xG models are complete "black-boxes", and fans often only see the final mysterious xG values quoted as single numbers. Therefore, this blog post serves as a comprehensive overview of an xG model I created using [Statsbomb's public data](https://github.com/statsbomb/open-data). More specifically, the model is created using data from Barcelona's La Liga matches from 2004 to 2016.

## Data exploration

Before thinking about the model, let's take a look at the data. The data is stored in json files on Statsbomb's public data repository on GitHub. The first step was extracting the information related to all the shots taken in Barcelona's La Liga matches from 2004 to 2016. I wrote a python script to do this, which spits out the information for all shots in a pandas dataframe. The next step was turning this information into useful variables that could be used to train a machine learning model - so-called "feature engineering". Some of the information which came directly from the json files were useful in their initial states, such as the x and y coordinates on the pitch from which the shots were taken, but other information needed to be manipulated to extract useful features. For example, most of the shots come with a "freeze frame", which contains the location on the pitch of each player when the shot was taken. I used this information to extract two features: the number of players between the shot location and the goal, and the number of opponents within a 5 yard radius of the shot location. In all, the final shot features are listed below:

- **play pattern**: pattern of play which led to the shot
- **x start location**: x-location of the shot 
- **y start location**: y-location of the shot 
- **duration**: duration of the shot
- **technique**: technique with which the shot was hit
- **first time**: whether the shot was hit first time or not
- **x gk position**: x-location of the gk when the shot was taken
- **y gk position**: y-location of the gk when the shot was taken
- **type of shot**: whether the shot was from open play or from a set piece (with type of set piece specified)
- **num opponents within 5 yards**: number of opponents which were within 5 yards of the shot location
- **num opponents between shot and goal**: number of opponents which were between the shot location, and the lines connecting the shot location and the two posts
- **outcome**: result of the shot (Goal or not Goal)

### Visualizing features

With the shot features extracted, I performed some data visualization to get a sense of how each one affects the probability of a shot resulting in a goal. Despite the fact that machine learning algorithms automatically select the most important features, this sort of exercise is useful as it provides an intuitive idea of what the models will eventually be doing. Let's first look at how the distance from which the shot was taken affects the goal scoring rate. 

![_config.yml]({{ site.baseurl }}/images/distance-vs-outcome.png)

We can see, unsurprisingly, that the further away a shot is taken, the less likely it is to result in a goal. However, we can also see that the relationship appears to be non-linear, and so a model capable of capturing non-linear relationships may perform best for predicting expected goals. Next, let's look at how the play pattern which led to the shot affects the goal scoring rate.

![_config.yml]({{ site.baseurl }}/images/play-pattern-vs-outcome.png)

Here, we see that "other" (penalties) result in goals about 70% of the time. The next best play pattern is counter attacks, where we see that shots from counters go in over 20% of the time. So it seems like shots from counters are of higher quality than shots created from other play patterns. The visualization below may explain why this is the case, where we see that on average, there are less opponents between the shot location and the goal for shots created from counters. This makes sense since many opposition players would be out of position in counter attacking situations. 

![_config.yml]({{ site.baseurl }}/images/play-pattern-num-players.png)

These are just a few of the shot feature relationships I visualized. For a more comprehensive EDA, see [this jupyter notebook](https://github.com/RobBlumberg/xg_model/blob/master/src/xg_model.ipynb) in the GitHub repo. 

## Training models

## Conclusion

